---
title: The Optimality of Jeffreys Prior for Online Density Estimation and the Asymptotic
  Normality of Maximum Likelihood Estimators
abstract: We study online learning under logarithmic loss with regular parametric
  models. We show that a Bayesian strategy predicts optimally only if it uses Jeffreys
  prior. This result was known for canonical exponential families; we extend it to
  parametric models for which the maximum likelihood estimator is asymptotically normal.
  The optimal prediction strategy, normalized maximum likelihood, depends on the number
  \emphn of rounds of the game, in general. However, when a Bayesian strategy is optimal,
  normalized maximum likelihood becomes independent of \emphn. Our proof uses this
  to exploit the asymptotics of normalized maximum likelihood. The asymptotic normality
  of the maximum likelihood estimator is responsible for the necessity of Jeffreys
  prior.
pdf: http://proceedings.mlr.press/v23/hedayati12/hedayati12.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hedayati12
month: 0
firstpage: 7
lastpage: 7
page: 7-7
sections: 
author:
- given: Fares
  family: Hedayati
- given: Peter L.
  family: Bartlett
date: 2012-06-16
address: Edinburgh, Scotland
publisher: PMLR
container-title: Proceedings of the 25th Annual Conference on Learning Theory
volume: '23'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 6
  - 16
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
