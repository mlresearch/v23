---
title: Generalization Bounds for Online Learning Algorithms with Pairwise Loss Functions
abstract: Efficient online learning with pairwise loss functions is a crucial component
  in building largescale learning system that maximizes the area under the Receiver
  Operator Characteristic (ROC) curve. In this paper we investigate the generalization
  performance of online learning algorithms with pairwise loss functions. We show
  that the existing proof techniques for generalization bounds of online algorithms
  with a pointwise loss can not be directly applied to pairwise losses. Using the
  Hoeffding-Azuma inequality and various proof techniques for the risk bounds in the
  batch learning, we derive data-dependent bounds for the average risk of the sequence
  of hypotheses generated by an arbitrary online learner in terms of an easily computable
  statistic, and show how to extract a low risk hypothesis from the sequence. In addition,
  we analyze a natural extension of the perceptron algorithm for the bipartite ranking
  problem providing a bound on the empirical pairwise loss. Combining these results
  we get a complete risk analysis of the proposed algorithm.
pdf: "./wang12/wang12.pdf"
layout: inproceedings
key: wang12
month: 0
firstpage: 13
lastpage: 13
origpdf: http://jmlr.org/proceedings/papers/v23/wang12/wang12.pdf
sections: 
authors:
- given: Yuyang
  family: Wang
- given: Roni
  family: Khardon
- given: Dmitry
  family: Pechyony
- given: Rosie
  family: Jones
---
