---
title: Divergences and Risks for Multiclass Experiments
abstract: Csiszár’s \emphf-divergence is a way to measure the similarity of two probability
  distributions. We study the extension of \emphf-divergence to more than two distributions
  to measure their joint similarity. By exploiting classical results from the comparison
  of experiments literature we prove the resulting divergence satisfies all the same
  properties as the traditional binary one. Considering the multidistribution case
  actually makes the proofs simpler. The key to these results is a formal bridge between
  these multidistribution \emphf-divergences and Bayes risks for multiclass classification
  problems.
pdf: http://proceedings.mlr.press/v23/garcia12/garcia12.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: garcia12
month: 0
tex_title: Divergences and Risks for Multiclass Experiments
firstpage: '28.1'
lastpage: '28.20'
page: 28.1-28.20
order: 28
cycles: false
author:
- given: Dario García
  family: García
- given: Robert C.
  family: Williamson
date: 2012-06-16
address: Edinburgh, Scotland
publisher: PMLR
container-title: Proceedings of the 25th Annual Conference on Learning Theory
volume: '23'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 6
  - 16
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
