<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<link rel="alternate" type="application/rss+xml" href="http://www.jmlr.org/jmlr.xml" title="JMLR RSS">
<style>. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>
<style type="text/css">
<!-- 
#fixed {
    position: absolute;
    top: 0;
    left: 0;
    width: 8em;
    height: 100%;
}
body > #fixed {
    position: fixed;
}
#content {
    margin-top: 1em;
    margin-left: 10em;
    margin-right: 0.5em;
}
img.jmlr {
    width: 7em;
}
img.rss {
    width: 2em;
}
-->
</style>
<script language="JavaScript"> 
<!-- function GoAddress(user,machine) {
document.location = 'mailto:' + user + '@' + machine; } 
// -->
</script>


<style>
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>

<div id="content">
<h2>Rare Probability Estimation
under Regularly Varying Heavy Tails</h2>
<p><b><i>Mesrob
  I. Ohannessian and Munther A. Dahleh</i></b><i> </i>JMLR W&amp;CP 23: 21.1 - 21.24, 2012</p>
<h3>Abstract</h3>
<p>This paper studies the problem of estimating the probability of symbols that have occurred very
rarely, in samples drawn independently from an unknown, possibly infinite, discrete distribution. In
particular, we study the multiplicative consistency of estimators, defined as the ratio of the estimate
to the true quantity converging to one. We first show that the classical Good-Turing estimator is
not universally consistent in this sense, despite enjoying favorable additive properties. We then use
Karamata's theory of regular variation to prove that regularly varying heavy tails are sufficient for
consistency. At the core of this result is a multiplicative concentration that we establish both by
extending the McAllester-Ortiz additive concentration for the missing mass to all rare probabilities
and by exploiting regular variation. We also derive a family of estimators which, in addition to
being consistent, address some of the shortcomings of the Good-Turing estimator. For example,
they perform smoothing implicitly and have the absolute discounting structure of many heuristic
algorithms. This also establishes a discrete parallel to extreme value theory, and many of the
techniques therein can be adapted to the framework that we set forth.</p>
</div>
 <div id="fixed">
<br>
<a align="right" href="http://www.jmlr.org/" target="_top"><img class="jmlr" src="http://jmlr.csail.mit.edu/jmlr.jpg" align="right" border="0"></a>
<p><br><br>
</p><p align="right"> <a href="http://www.jmlr.org/"> Home Page </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/papers"> Papers </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/author-info.html"> Submissions </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/news.html"> News </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/scope.html"> Scope </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/editorial-board.html"> Editorial Board </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/announcements.html"> Announcements </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/proceedings"> Proceedings </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/mloss">Open Source Software</a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/search-jmlr.html"> Search </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/manudb"> Login </a></p>

<br><br>
<p align="right"> <a href="http://jmlr.csail.mit.edu/jmlr.xml"> 
<img src="http://jmlr.csail.mit.edu/RSS.gif" class="rss" alt="RSS Feed">
</a>



</p></div>
 
<p></p><center>Page last modified on Sat June 16 2012 22:30 2012.</center>

<p> 

<table width="100%"> <tbody><tr>
<td align="right"><font size="-1">Copyright 
@ <a target="_top" href="http://www.jmlr.org/">JMLR</a> 2012.  All rights
reserved.</font></td> </tr> </tbody></table>
</p></body></html>